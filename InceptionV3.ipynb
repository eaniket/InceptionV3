{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PtnV2LO3Jkv5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\us\\Anaconda3\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n",
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\us\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as k\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vx3oMV14Jml_"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-bbd59b6a3440>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_remount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yqvSDZB1JpH7"
   },
   "outputs": [],
   "source": [
    "nb_classes = 5  # number of classes\n",
    "based_model_last_block_layer_number = 126  # value is based on based model selected.\n",
    "img_width, img_height = 299, 299  # change based on the shape/structure of your images\n",
    "batch_size = 32  \n",
    "nb_epoch = 50  \n",
    "learn_rate = 1e-4  \n",
    "momentum = .9 \n",
    "transformation_ratio = .05  \n",
    "nb_train_samples = 3682  \n",
    "nb_validation_samples = 584  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hhB5Jl2lJ5n3"
   },
   "outputs": [],
   "source": [
    "def train(train_data_dir, validation_data_dir, model_path):\n",
    "    \n",
    "    \n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (3, img_width, img_height)\n",
    "    else:\n",
    "        input_shape = (img_width, img_height, 3)\n",
    "   \n",
    "    base_model = InceptionV3(input_shape=input_shape, weights='imagenet', include_top=False)\n",
    "\n",
    "    # # Top Model Block    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D((x)\n",
    "    \n",
    "    x = Dense(256, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    predictions = Dense(nb_classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "  \n",
    "    model = Model(base_model.input, predictions)\n",
    "    print(model.summary())\n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Data augmentation \n",
    "    train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                       rotation_range=transformation_ratio,\n",
    "                                       shear_range=transformation_ratio,\n",
    "                                       zoom_range=transformation_ratio,\n",
    "                                       cval=transformation_ratio,\n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True)\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "  \n",
    "    train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                        target_size=[img_width, img_height],\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        class_mode='categorical')\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                                  target_size=[img_width, img_height],\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='categorical')\n",
    "    # Model compiling\n",
    "    model.compile(optimizer='nadam',\n",
    "                  loss='categorical_crossentropy',  # categorical_crossentropy if multi-class classifier\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # save weights of best training epoch\n",
    "\n",
    "    top_weights_path = os.path.join(os.path.abspath(model_path), 'top_model_weights.h5')\n",
    "    \n",
    "    from PIL import ImageFile\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "    # Train Simple CNN\n",
    "    model.fit_generator(train_generator,\n",
    "                        steps_per_epoch=nb_train_samples // batch_size,\n",
    "                        epochs=nb_epoch / 4,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=nb_validation_samples // batch_size\n",
    "                     \n",
    "                        )\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FKJaaakeKFPe"
   },
   "outputs": [],
   "source": [
    "train_path = 'gdrive/My Drive/image_dataset/data_set/'\n",
    "test_path = 'gdrive/My Drive/testdata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_path.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FGaseGtCKKeM"
   },
   "outputs": [],
   "source": [
    "model = train(train_path, test_path, \"gdrive/My Drive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VufsVjRRKNeW"
   },
   "outputs": [],
   "source": [
    "model.save(\"gdrive/My Drive/inception.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XqcOhM00KRMX"
   },
   "outputs": [],
   "source": [
    "layer_name = \"mixed10\"\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "print(intermediate_layer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4k4wz_qCKUuK"
   },
   "outputs": [],
   "source": [
    "li=[]\n",
    "img_path = \"gdrive/My Drive/testdata/shoes/00000302.jpg\"            \n",
    "image2 = image.load_img(img_path, target_size=(299,299))\n",
    "image2 = image.img_to_array(image2)\n",
    "print(image2.shape)\n",
    "image2 = np.expand_dims(image2, axis=0)\n",
    "print(image2.shape)\n",
    "image2 = preprocess_input(image2)\n",
    "intermediate_output = intermediate_layer_model.predict(image2)\n",
    "print(intermediate_output)\n",
    "li.append(intermediate_output)\n",
    "print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MNoKPRGDKZ9o"
   },
   "outputs": [],
   "source": [
    "#for output, change this image path\n",
    "\n",
    "\n",
    "img_path = \"gdrive/My Drive/testdata/shoes/00000302.jpg\"\n",
    "            \n",
    "image2 = image.load_img(img_path, target_size=(299,299))\n",
    "image2 = image.img_to_array(image2)\n",
    "print(image2.shape)\n",
    "image2 = np.expand_dims(image2, axis=0)\n",
    "print(image2.shape)\n",
    "image2 = preprocess_input(image2)\n",
    "output = model.predict(image2)\n",
    "print(output[0])\n",
    "lis = list(output[0])\n",
    "out = (max(output[0]))\n",
    "print(out)\n",
    "l = lis.index(out)\n",
    "print(l)\n",
    "if l == 0:\n",
    "  print(\"its a dress\")\n",
    "  #auto encoder for dress\n",
    "elif l == 1:\n",
    "   print(\"its a shirt\")\n",
    "  #autoencoder for shirt\n",
    "elif l == 2 :\n",
    "   print(\"its a shoe\")\n",
    "  #autoencoder for shoe\n",
    "else:\n",
    "   print(\"its a short\")\n",
    "  # autoencoder for short"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of Untitled8.ipynb",
   "provenance": [
    {
     "file_id": "1w80kASmBKbhz-pamfVwnSjph3MhwNYWi",
     "timestamp": 1555317776732
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
