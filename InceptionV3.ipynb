{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled8.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eaniket/InceptionV3/blob/master/InceptionV3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PtnV2LO3Jkv5",
        "scrolled": true,
        "colab": {},
        "outputId": "c23e9638-6785-4005-b8d1-b1d6bc5669ca"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.applications import *\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras import backend as k\n",
        "import keras\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import preprocess_input"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\us\\Anaconda3\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
            "                the kernel may be left running.  Please let us know\n",
            "                about your system (bitness, Python, etc.) at\n",
            "                ipython-dev@scipy.org\n",
            "  ipython-dev@scipy.org\"\"\")\n",
            "Using Theano backend.\n",
            "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
            "C:\\Users\\us\\Anaconda3\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
            "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
            "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
            "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vx3oMV14Jml_",
        "colab": {},
        "outputId": "504dd5e1-2d78-4abc-964a-7995f5965449"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-5-bbd59b6a3440>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_remount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yqvSDZB1JpH7",
        "colab": {}
      },
      "source": [
        "nb_classes = 5  # number of classes\n",
        "based_model_last_block_layer_number = 126  # value is based on based model selected.\n",
        "img_width, img_height = 299, 299  # change based on the shape/structure of your images\n",
        "batch_size = 32  \n",
        "nb_epoch = 50  \n",
        "learn_rate = 1e-4  \n",
        "momentum = .9 \n",
        "transformation_ratio = .05  \n",
        "nb_train_samples = 3682  \n",
        "nb_validation_samples = 584  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hhB5Jl2lJ5n3",
        "colab": {}
      },
      "source": [
        "def train(train_data_dir, validation_data_dir, model_path):\n",
        "    \n",
        "    \n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        input_shape = (3, img_width, img_height)\n",
        "    else:\n",
        "        input_shape = (img_width, img_height, 3)\n",
        "   \n",
        "    base_model = InceptionV3(input_shape=input_shape, weights='imagenet', include_top=False)\n",
        "\n",
        "    # # Top Model Block    \n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D((x)\n",
        "    \n",
        "    x = Dense(256, activation='relu', name='fc1')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    predictions = Dense(nb_classes, activation='softmax', name='predictions')(x)\n",
        "\n",
        "  \n",
        "    model = Model(base_model.input, predictions)\n",
        "    print(model.summary())\n",
        "    \n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Data augmentation \n",
        "    train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "                                       rotation_range=transformation_ratio,\n",
        "                                       shear_range=transformation_ratio,\n",
        "                                       zoom_range=transformation_ratio,\n",
        "                                       cval=transformation_ratio,\n",
        "                                       horizontal_flip=True,\n",
        "                                       vertical_flip=True)\n",
        "\n",
        "    validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "  \n",
        "    train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                        target_size=[img_width, img_height],\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        class_mode='categorical')\n",
        "\n",
        "    validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
        "                                                                  target_size=[img_width, img_height],\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='categorical')\n",
        "    # Model compiling\n",
        "    model.compile(optimizer='nadam',\n",
        "                  loss='categorical_crossentropy',  # categorical_crossentropy if multi-class classifier\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # save weights of best training epoch\n",
        "\n",
        "    top_weights_path = os.path.join(os.path.abspath(model_path), 'top_model_weights.h5')\n",
        "    \n",
        "    from PIL import ImageFile\n",
        "    ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "    # Train Simple CNN\n",
        "    model.fit_generator(train_generator,\n",
        "                        steps_per_epoch=nb_train_samples // batch_size,\n",
        "                        epochs=nb_epoch / 4,\n",
        "                        validation_data=validation_generator,\n",
        "                        validation_steps=nb_validation_samples // batch_size\n",
        "                     \n",
        "                        )\n",
        "    return model\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FKJaaakeKFPe",
        "colab": {}
      },
      "source": [
        "train_path = 'gdrive/My Drive/image_dataset/data_set/'\n",
        "test_path = 'gdrive/My Drive/testdata/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfIF-r21jaWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_path.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FGaseGtCKKeM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8c76775-937c-49dc-ee73-371545f15e00"
      },
      "source": [
        "model = train(train_path, test_path, \"gdrive/My Drive/\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_377 (Conv2D)             (None, 149, 149, 32) 864         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_377 (BatchN (None, 149, 149, 32) 96          conv2d_377[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_377 (Activation)     (None, 149, 149, 32) 0           batch_normalization_377[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_378 (Conv2D)             (None, 147, 147, 32) 9216        activation_377[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_378 (BatchN (None, 147, 147, 32) 96          conv2d_378[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_378 (Activation)     (None, 147, 147, 32) 0           batch_normalization_378[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_379 (Conv2D)             (None, 147, 147, 64) 18432       activation_378[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_379 (BatchN (None, 147, 147, 64) 192         conv2d_379[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_379 (Activation)     (None, 147, 147, 64) 0           batch_normalization_379[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 73, 73, 64)   0           activation_379[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_380 (Conv2D)             (None, 73, 73, 80)   5120        max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_380 (BatchN (None, 73, 73, 80)   240         conv2d_380[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_380 (Activation)     (None, 73, 73, 80)   0           batch_normalization_380[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_381 (Conv2D)             (None, 71, 71, 192)  138240      activation_380[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_381 (BatchN (None, 71, 71, 192)  576         conv2d_381[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_381 (Activation)     (None, 71, 71, 192)  0           batch_normalization_381[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling2D) (None, 35, 35, 192)  0           activation_381[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_385 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_385 (BatchN (None, 35, 35, 64)   192         conv2d_385[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_385 (Activation)     (None, 35, 35, 64)   0           batch_normalization_385[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_383 (Conv2D)             (None, 35, 35, 48)   9216        max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_386 (Conv2D)             (None, 35, 35, 96)   55296       activation_385[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_383 (BatchN (None, 35, 35, 48)   144         conv2d_383[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_386 (BatchN (None, 35, 35, 96)   288         conv2d_386[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_383 (Activation)     (None, 35, 35, 48)   0           batch_normalization_383[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_386 (Activation)     (None, 35, 35, 96)   0           batch_normalization_386[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_37 (AveragePo (None, 35, 35, 192)  0           max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_382 (Conv2D)             (None, 35, 35, 64)   12288       max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_384 (Conv2D)             (None, 35, 35, 64)   76800       activation_383[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_387 (Conv2D)             (None, 35, 35, 96)   82944       activation_386[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_388 (Conv2D)             (None, 35, 35, 32)   6144        average_pooling2d_37[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_382 (BatchN (None, 35, 35, 64)   192         conv2d_382[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_384 (BatchN (None, 35, 35, 64)   192         conv2d_384[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_387 (BatchN (None, 35, 35, 96)   288         conv2d_387[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_388 (BatchN (None, 35, 35, 32)   96          conv2d_388[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_382 (Activation)     (None, 35, 35, 64)   0           batch_normalization_382[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_384 (Activation)     (None, 35, 35, 64)   0           batch_normalization_384[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_387 (Activation)     (None, 35, 35, 96)   0           batch_normalization_387[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_388 (Activation)     (None, 35, 35, 32)   0           batch_normalization_388[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_382[0][0]             \n",
            "                                                                 activation_384[0][0]             \n",
            "                                                                 activation_387[0][0]             \n",
            "                                                                 activation_388[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_392 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_392 (BatchN (None, 35, 35, 64)   192         conv2d_392[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_392 (Activation)     (None, 35, 35, 64)   0           batch_normalization_392[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_390 (Conv2D)             (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_393 (Conv2D)             (None, 35, 35, 96)   55296       activation_392[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_390 (BatchN (None, 35, 35, 48)   144         conv2d_390[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_393 (BatchN (None, 35, 35, 96)   288         conv2d_393[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_390 (Activation)     (None, 35, 35, 48)   0           batch_normalization_390[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_393 (Activation)     (None, 35, 35, 96)   0           batch_normalization_393[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_38 (AveragePo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_389 (Conv2D)             (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_391 (Conv2D)             (None, 35, 35, 64)   76800       activation_390[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_394 (Conv2D)             (None, 35, 35, 96)   82944       activation_393[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_395 (Conv2D)             (None, 35, 35, 64)   16384       average_pooling2d_38[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_389 (BatchN (None, 35, 35, 64)   192         conv2d_389[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_391 (BatchN (None, 35, 35, 64)   192         conv2d_391[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_394 (BatchN (None, 35, 35, 96)   288         conv2d_394[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_395 (BatchN (None, 35, 35, 64)   192         conv2d_395[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_389 (Activation)     (None, 35, 35, 64)   0           batch_normalization_389[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_391 (Activation)     (None, 35, 35, 64)   0           batch_normalization_391[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_394 (Activation)     (None, 35, 35, 96)   0           batch_normalization_394[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_395 (Activation)     (None, 35, 35, 64)   0           batch_normalization_395[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_389[0][0]             \n",
            "                                                                 activation_391[0][0]             \n",
            "                                                                 activation_394[0][0]             \n",
            "                                                                 activation_395[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_399 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_399 (BatchN (None, 35, 35, 64)   192         conv2d_399[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_399 (Activation)     (None, 35, 35, 64)   0           batch_normalization_399[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_397 (Conv2D)             (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_400 (Conv2D)             (None, 35, 35, 96)   55296       activation_399[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_397 (BatchN (None, 35, 35, 48)   144         conv2d_397[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_400 (BatchN (None, 35, 35, 96)   288         conv2d_400[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_397 (Activation)     (None, 35, 35, 48)   0           batch_normalization_397[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_400 (Activation)     (None, 35, 35, 96)   0           batch_normalization_400[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_39 (AveragePo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_396 (Conv2D)             (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_398 (Conv2D)             (None, 35, 35, 64)   76800       activation_397[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_401 (Conv2D)             (None, 35, 35, 96)   82944       activation_400[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_402 (Conv2D)             (None, 35, 35, 64)   18432       average_pooling2d_39[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_396 (BatchN (None, 35, 35, 64)   192         conv2d_396[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_398 (BatchN (None, 35, 35, 64)   192         conv2d_398[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_401 (BatchN (None, 35, 35, 96)   288         conv2d_401[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_402 (BatchN (None, 35, 35, 64)   192         conv2d_402[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_396 (Activation)     (None, 35, 35, 64)   0           batch_normalization_396[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_398 (Activation)     (None, 35, 35, 64)   0           batch_normalization_398[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_401 (Activation)     (None, 35, 35, 96)   0           batch_normalization_401[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_402 (Activation)     (None, 35, 35, 64)   0           batch_normalization_402[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_396[0][0]             \n",
            "                                                                 activation_398[0][0]             \n",
            "                                                                 activation_401[0][0]             \n",
            "                                                                 activation_402[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_404 (Conv2D)             (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_404 (BatchN (None, 35, 35, 64)   192         conv2d_404[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_404 (Activation)     (None, 35, 35, 64)   0           batch_normalization_404[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_405 (Conv2D)             (None, 35, 35, 96)   55296       activation_404[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_405 (BatchN (None, 35, 35, 96)   288         conv2d_405[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_405 (Activation)     (None, 35, 35, 96)   0           batch_normalization_405[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_403 (Conv2D)             (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_406 (Conv2D)             (None, 17, 17, 96)   82944       activation_405[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_403 (BatchN (None, 17, 17, 384)  1152        conv2d_403[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_406 (BatchN (None, 17, 17, 96)   288         conv2d_406[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_403 (Activation)     (None, 17, 17, 384)  0           batch_normalization_403[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_406 (Activation)     (None, 17, 17, 96)   0           batch_normalization_406[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_403[0][0]             \n",
            "                                                                 activation_406[0][0]             \n",
            "                                                                 max_pooling2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_411 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_411 (BatchN (None, 17, 17, 128)  384         conv2d_411[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_411 (Activation)     (None, 17, 17, 128)  0           batch_normalization_411[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_412 (Conv2D)             (None, 17, 17, 128)  114688      activation_411[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_412 (BatchN (None, 17, 17, 128)  384         conv2d_412[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_412 (Activation)     (None, 17, 17, 128)  0           batch_normalization_412[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_408 (Conv2D)             (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_413 (Conv2D)             (None, 17, 17, 128)  114688      activation_412[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_408 (BatchN (None, 17, 17, 128)  384         conv2d_408[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_413 (BatchN (None, 17, 17, 128)  384         conv2d_413[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_408 (Activation)     (None, 17, 17, 128)  0           batch_normalization_408[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_413 (Activation)     (None, 17, 17, 128)  0           batch_normalization_413[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_409 (Conv2D)             (None, 17, 17, 128)  114688      activation_408[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_414 (Conv2D)             (None, 17, 17, 128)  114688      activation_413[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_409 (BatchN (None, 17, 17, 128)  384         conv2d_409[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_414 (BatchN (None, 17, 17, 128)  384         conv2d_414[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_409 (Activation)     (None, 17, 17, 128)  0           batch_normalization_409[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_414 (Activation)     (None, 17, 17, 128)  0           batch_normalization_414[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_40 (AveragePo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_407 (Conv2D)             (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_410 (Conv2D)             (None, 17, 17, 192)  172032      activation_409[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_415 (Conv2D)             (None, 17, 17, 192)  172032      activation_414[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_416 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_40[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_407 (BatchN (None, 17, 17, 192)  576         conv2d_407[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_410 (BatchN (None, 17, 17, 192)  576         conv2d_410[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_415 (BatchN (None, 17, 17, 192)  576         conv2d_415[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_416 (BatchN (None, 17, 17, 192)  576         conv2d_416[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_407 (Activation)     (None, 17, 17, 192)  0           batch_normalization_407[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_410 (Activation)     (None, 17, 17, 192)  0           batch_normalization_410[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_415 (Activation)     (None, 17, 17, 192)  0           batch_normalization_415[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_416 (Activation)     (None, 17, 17, 192)  0           batch_normalization_416[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_407[0][0]             \n",
            "                                                                 activation_410[0][0]             \n",
            "                                                                 activation_415[0][0]             \n",
            "                                                                 activation_416[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_421 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_421 (BatchN (None, 17, 17, 160)  480         conv2d_421[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_421 (Activation)     (None, 17, 17, 160)  0           batch_normalization_421[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_422 (Conv2D)             (None, 17, 17, 160)  179200      activation_421[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_422 (BatchN (None, 17, 17, 160)  480         conv2d_422[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_422 (Activation)     (None, 17, 17, 160)  0           batch_normalization_422[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_418 (Conv2D)             (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_423 (Conv2D)             (None, 17, 17, 160)  179200      activation_422[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_418 (BatchN (None, 17, 17, 160)  480         conv2d_418[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_423 (BatchN (None, 17, 17, 160)  480         conv2d_423[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_418 (Activation)     (None, 17, 17, 160)  0           batch_normalization_418[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_423 (Activation)     (None, 17, 17, 160)  0           batch_normalization_423[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_419 (Conv2D)             (None, 17, 17, 160)  179200      activation_418[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_424 (Conv2D)             (None, 17, 17, 160)  179200      activation_423[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_419 (BatchN (None, 17, 17, 160)  480         conv2d_419[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_424 (BatchN (None, 17, 17, 160)  480         conv2d_424[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_419 (Activation)     (None, 17, 17, 160)  0           batch_normalization_419[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_424 (Activation)     (None, 17, 17, 160)  0           batch_normalization_424[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_41 (AveragePo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_417 (Conv2D)             (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_420 (Conv2D)             (None, 17, 17, 192)  215040      activation_419[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_425 (Conv2D)             (None, 17, 17, 192)  215040      activation_424[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_426 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_41[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_417 (BatchN (None, 17, 17, 192)  576         conv2d_417[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_420 (BatchN (None, 17, 17, 192)  576         conv2d_420[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_425 (BatchN (None, 17, 17, 192)  576         conv2d_425[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_426 (BatchN (None, 17, 17, 192)  576         conv2d_426[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_417 (Activation)     (None, 17, 17, 192)  0           batch_normalization_417[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_420 (Activation)     (None, 17, 17, 192)  0           batch_normalization_420[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_425 (Activation)     (None, 17, 17, 192)  0           batch_normalization_425[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_426 (Activation)     (None, 17, 17, 192)  0           batch_normalization_426[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_417[0][0]             \n",
            "                                                                 activation_420[0][0]             \n",
            "                                                                 activation_425[0][0]             \n",
            "                                                                 activation_426[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_431 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_431 (BatchN (None, 17, 17, 160)  480         conv2d_431[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_431 (Activation)     (None, 17, 17, 160)  0           batch_normalization_431[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_432 (Conv2D)             (None, 17, 17, 160)  179200      activation_431[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_432 (BatchN (None, 17, 17, 160)  480         conv2d_432[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_432 (Activation)     (None, 17, 17, 160)  0           batch_normalization_432[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_428 (Conv2D)             (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_433 (Conv2D)             (None, 17, 17, 160)  179200      activation_432[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_428 (BatchN (None, 17, 17, 160)  480         conv2d_428[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_433 (BatchN (None, 17, 17, 160)  480         conv2d_433[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_428 (Activation)     (None, 17, 17, 160)  0           batch_normalization_428[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_433 (Activation)     (None, 17, 17, 160)  0           batch_normalization_433[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_429 (Conv2D)             (None, 17, 17, 160)  179200      activation_428[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_434 (Conv2D)             (None, 17, 17, 160)  179200      activation_433[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_429 (BatchN (None, 17, 17, 160)  480         conv2d_429[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_434 (BatchN (None, 17, 17, 160)  480         conv2d_434[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_429 (Activation)     (None, 17, 17, 160)  0           batch_normalization_429[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_434 (Activation)     (None, 17, 17, 160)  0           batch_normalization_434[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_42 (AveragePo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_427 (Conv2D)             (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_430 (Conv2D)             (None, 17, 17, 192)  215040      activation_429[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_435 (Conv2D)             (None, 17, 17, 192)  215040      activation_434[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_436 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_42[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_427 (BatchN (None, 17, 17, 192)  576         conv2d_427[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_430 (BatchN (None, 17, 17, 192)  576         conv2d_430[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_435 (BatchN (None, 17, 17, 192)  576         conv2d_435[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_436 (BatchN (None, 17, 17, 192)  576         conv2d_436[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_427 (Activation)     (None, 17, 17, 192)  0           batch_normalization_427[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_430 (Activation)     (None, 17, 17, 192)  0           batch_normalization_430[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_435 (Activation)     (None, 17, 17, 192)  0           batch_normalization_435[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_436 (Activation)     (None, 17, 17, 192)  0           batch_normalization_436[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_427[0][0]             \n",
            "                                                                 activation_430[0][0]             \n",
            "                                                                 activation_435[0][0]             \n",
            "                                                                 activation_436[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_441 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_441 (BatchN (None, 17, 17, 192)  576         conv2d_441[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_441 (Activation)     (None, 17, 17, 192)  0           batch_normalization_441[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_442 (Conv2D)             (None, 17, 17, 192)  258048      activation_441[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_442 (BatchN (None, 17, 17, 192)  576         conv2d_442[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_442 (Activation)     (None, 17, 17, 192)  0           batch_normalization_442[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_438 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_443 (Conv2D)             (None, 17, 17, 192)  258048      activation_442[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_438 (BatchN (None, 17, 17, 192)  576         conv2d_438[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_443 (BatchN (None, 17, 17, 192)  576         conv2d_443[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_438 (Activation)     (None, 17, 17, 192)  0           batch_normalization_438[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_443 (Activation)     (None, 17, 17, 192)  0           batch_normalization_443[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_439 (Conv2D)             (None, 17, 17, 192)  258048      activation_438[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_444 (Conv2D)             (None, 17, 17, 192)  258048      activation_443[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_439 (BatchN (None, 17, 17, 192)  576         conv2d_439[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_444 (BatchN (None, 17, 17, 192)  576         conv2d_444[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_439 (Activation)     (None, 17, 17, 192)  0           batch_normalization_439[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_444 (Activation)     (None, 17, 17, 192)  0           batch_normalization_444[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_43 (AveragePo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_437 (Conv2D)             (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_440 (Conv2D)             (None, 17, 17, 192)  258048      activation_439[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_445 (Conv2D)             (None, 17, 17, 192)  258048      activation_444[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_446 (Conv2D)             (None, 17, 17, 192)  147456      average_pooling2d_43[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_437 (BatchN (None, 17, 17, 192)  576         conv2d_437[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_440 (BatchN (None, 17, 17, 192)  576         conv2d_440[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_445 (BatchN (None, 17, 17, 192)  576         conv2d_445[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_446 (BatchN (None, 17, 17, 192)  576         conv2d_446[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_437 (Activation)     (None, 17, 17, 192)  0           batch_normalization_437[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_440 (Activation)     (None, 17, 17, 192)  0           batch_normalization_440[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_445 (Activation)     (None, 17, 17, 192)  0           batch_normalization_445[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_446 (Activation)     (None, 17, 17, 192)  0           batch_normalization_446[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_437[0][0]             \n",
            "                                                                 activation_440[0][0]             \n",
            "                                                                 activation_445[0][0]             \n",
            "                                                                 activation_446[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_449 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_449 (BatchN (None, 17, 17, 192)  576         conv2d_449[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_449 (Activation)     (None, 17, 17, 192)  0           batch_normalization_449[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_450 (Conv2D)             (None, 17, 17, 192)  258048      activation_449[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_450 (BatchN (None, 17, 17, 192)  576         conv2d_450[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_450 (Activation)     (None, 17, 17, 192)  0           batch_normalization_450[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_447 (Conv2D)             (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_451 (Conv2D)             (None, 17, 17, 192)  258048      activation_450[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_447 (BatchN (None, 17, 17, 192)  576         conv2d_447[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_451 (BatchN (None, 17, 17, 192)  576         conv2d_451[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_447 (Activation)     (None, 17, 17, 192)  0           batch_normalization_447[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_451 (Activation)     (None, 17, 17, 192)  0           batch_normalization_451[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_448 (Conv2D)             (None, 8, 8, 320)    552960      activation_447[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_452 (Conv2D)             (None, 8, 8, 192)    331776      activation_451[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_448 (BatchN (None, 8, 8, 320)    960         conv2d_448[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_452 (BatchN (None, 8, 8, 192)    576         conv2d_452[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_448 (Activation)     (None, 8, 8, 320)    0           batch_normalization_448[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_452 (Activation)     (None, 8, 8, 192)    0           batch_normalization_452[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_20 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_448[0][0]             \n",
            "                                                                 activation_452[0][0]             \n",
            "                                                                 max_pooling2d_20[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_457 (Conv2D)             (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_457 (BatchN (None, 8, 8, 448)    1344        conv2d_457[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_457 (Activation)     (None, 8, 8, 448)    0           batch_normalization_457[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_454 (Conv2D)             (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_458 (Conv2D)             (None, 8, 8, 384)    1548288     activation_457[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_454 (BatchN (None, 8, 8, 384)    1152        conv2d_454[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_458 (BatchN (None, 8, 8, 384)    1152        conv2d_458[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_454 (Activation)     (None, 8, 8, 384)    0           batch_normalization_454[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_458 (Activation)     (None, 8, 8, 384)    0           batch_normalization_458[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_455 (Conv2D)             (None, 8, 8, 384)    442368      activation_454[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_456 (Conv2D)             (None, 8, 8, 384)    442368      activation_454[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_459 (Conv2D)             (None, 8, 8, 384)    442368      activation_458[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_460 (Conv2D)             (None, 8, 8, 384)    442368      activation_458[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_44 (AveragePo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_453 (Conv2D)             (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_455 (BatchN (None, 8, 8, 384)    1152        conv2d_455[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_456 (BatchN (None, 8, 8, 384)    1152        conv2d_456[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_459 (BatchN (None, 8, 8, 384)    1152        conv2d_459[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_460 (BatchN (None, 8, 8, 384)    1152        conv2d_460[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_461 (Conv2D)             (None, 8, 8, 192)    245760      average_pooling2d_44[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_453 (BatchN (None, 8, 8, 320)    960         conv2d_453[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_455 (Activation)     (None, 8, 8, 384)    0           batch_normalization_455[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_456 (Activation)     (None, 8, 8, 384)    0           batch_normalization_456[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_459 (Activation)     (None, 8, 8, 384)    0           batch_normalization_459[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_460 (Activation)     (None, 8, 8, 384)    0           batch_normalization_460[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_461 (BatchN (None, 8, 8, 192)    576         conv2d_461[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_453 (Activation)     (None, 8, 8, 320)    0           batch_normalization_453[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_455[0][0]             \n",
            "                                                                 activation_456[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 8, 8, 768)    0           activation_459[0][0]             \n",
            "                                                                 activation_460[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_461 (Activation)     (None, 8, 8, 192)    0           batch_normalization_461[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_453[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_9[0][0]              \n",
            "                                                                 activation_461[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_466 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_466 (BatchN (None, 8, 8, 448)    1344        conv2d_466[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_466 (Activation)     (None, 8, 8, 448)    0           batch_normalization_466[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_463 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_467 (Conv2D)             (None, 8, 8, 384)    1548288     activation_466[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_463 (BatchN (None, 8, 8, 384)    1152        conv2d_463[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_467 (BatchN (None, 8, 8, 384)    1152        conv2d_467[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_463 (Activation)     (None, 8, 8, 384)    0           batch_normalization_463[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_467 (Activation)     (None, 8, 8, 384)    0           batch_normalization_467[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_464 (Conv2D)             (None, 8, 8, 384)    442368      activation_463[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_465 (Conv2D)             (None, 8, 8, 384)    442368      activation_463[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_468 (Conv2D)             (None, 8, 8, 384)    442368      activation_467[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_469 (Conv2D)             (None, 8, 8, 384)    442368      activation_467[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_45 (AveragePo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_462 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_464 (BatchN (None, 8, 8, 384)    1152        conv2d_464[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_465 (BatchN (None, 8, 8, 384)    1152        conv2d_465[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_468 (BatchN (None, 8, 8, 384)    1152        conv2d_468[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_469 (BatchN (None, 8, 8, 384)    1152        conv2d_469[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_470 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_45[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_462 (BatchN (None, 8, 8, 320)    960         conv2d_462[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_464 (Activation)     (None, 8, 8, 384)    0           batch_normalization_464[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_465 (Activation)     (None, 8, 8, 384)    0           batch_normalization_465[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_468 (Activation)     (None, 8, 8, 384)    0           batch_normalization_468[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_469 (Activation)     (None, 8, 8, 384)    0           batch_normalization_469[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_470 (BatchN (None, 8, 8, 192)    576         conv2d_470[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_462 (Activation)     (None, 8, 8, 320)    0           batch_normalization_462[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_464[0][0]             \n",
            "                                                                 activation_465[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 8, 8, 768)    0           activation_468[0][0]             \n",
            "                                                                 activation_469[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_470 (Activation)     (None, 8, 8, 192)    0           batch_normalization_470[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_462[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_10[0][0]             \n",
            "                                                                 activation_470[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_5 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc1 (Dense)                     (None, 256)          524544      global_average_pooling2d_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 256)          0           fc1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 5)            1285        dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 22,328,613\n",
            "Trainable params: 22,294,181\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Found 3987 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0630 08:41:57.341848 139844732229504 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0630 08:41:57.488650 139844732229504 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 3987 images belonging to 5 classes.\n",
            "Epoch 1/12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:914: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
            "  'to RGBA images')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "115/115 [==============================] - 1530s 13s/step - loss: 0.9191 - acc: 0.6891 - val_loss: 0.2681 - val_acc: 0.8924\n",
            "Epoch 2/12\n",
            "115/115 [==============================] - 1249s 11s/step - loss: 0.4751 - acc: 0.8315 - val_loss: 0.2810 - val_acc: 0.8889\n",
            "Epoch 3/12\n",
            "115/115 [==============================] - 1330s 12s/step - loss: 0.4090 - acc: 0.8518 - val_loss: 0.1967 - val_acc: 0.9219\n",
            "Epoch 4/12\n",
            "115/115 [==============================] - 1350s 12s/step - loss: 0.4047 - acc: 0.8552 - val_loss: 0.1422 - val_acc: 0.9497\n",
            "Epoch 5/12\n",
            "115/115 [==============================] - 1364s 12s/step - loss: 0.3727 - acc: 0.8670 - val_loss: 0.2222 - val_acc: 0.9080\n",
            "Epoch 6/12\n",
            "115/115 [==============================] - 1370s 12s/step - loss: 0.3407 - acc: 0.8739 - val_loss: 0.1027 - val_acc: 0.9740\n",
            "Epoch 7/12\n",
            "115/115 [==============================] - 1356s 12s/step - loss: 0.3254 - acc: 0.8812 - val_loss: 0.2210 - val_acc: 0.9165\n",
            "Epoch 8/12\n",
            "115/115 [==============================] - 1356s 12s/step - loss: 0.3275 - acc: 0.8809 - val_loss: 0.1396 - val_acc: 0.9444\n",
            "Epoch 9/12\n",
            "115/115 [==============================] - 1347s 12s/step - loss: 0.3177 - acc: 0.8875 - val_loss: 0.1894 - val_acc: 0.9566\n",
            "Epoch 10/12\n",
            "115/115 [==============================] - 1351s 12s/step - loss: 0.3008 - acc: 0.8894 - val_loss: 0.1038 - val_acc: 0.9601\n",
            "Epoch 11/12\n",
            "115/115 [==============================] - 1366s 12s/step - loss: 0.2933 - acc: 0.8933 - val_loss: 0.1640 - val_acc: 0.9375\n",
            "Epoch 12/12\n",
            "115/115 [==============================] - 1378s 12s/step - loss: 0.2960 - acc: 0.8962 - val_loss: 0.0792 - val_acc: 0.9774\n",
            "Epoch 13/12\n",
            "115/115 [==============================] - 1379s 12s/step - loss: 0.3088 - acc: 0.8899 - val_loss: 0.0975 - val_acc: 0.9757\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VufsVjRRKNeW",
        "colab": {}
      },
      "source": [
        "model.save(\"gdrive/My Drive/inception.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XqcOhM00KRMX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9b75211d-9cb2-4122-d80b-5f0dc2f725f3"
      },
      "source": [
        "layer_name = \"mixed10\"\n",
        "intermediate_layer_model = Model(inputs=model.input,\n",
        "                                 outputs=model.get_layer(layer_name).output)\n",
        "print(intermediate_layer_model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<keras.engine.training.Model object at 0x7f2fc4834940>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4k4wz_qCKUuK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b94f6427-3b32-4e2b-e04d-9c538ea92593"
      },
      "source": [
        "li=[]\n",
        "img_path = \"gdrive/My Drive/image_dataset/data_set/shoes/00000302.jpg\"            \n",
        "image2 = image.load_img(img_path, target_size=(299,299))\n",
        "image2 = image.img_to_array(image2)\n",
        "print(image2.shape)\n",
        "image2 = np.expand_dims(image2, axis=0)\n",
        "print(image2.shape)\n",
        "image2 = preprocess_input(image2)\n",
        "intermediate_output = intermediate_layer_model.predict(image2)\n",
        "print(intermediate_output)\n",
        "li.append(intermediate_output)\n",
        "print(li)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(299, 299, 3)\n",
            "(1, 299, 299, 3)\n",
            "[[[[0.00000000e+00 4.31867003e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 1.26274526e-01 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   ...\n",
            "   [1.54062402e+00 4.78087544e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    7.73721933e-01 2.30732709e-01]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 2.23332345e-01 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   ...\n",
            "   [4.26317501e+00 0.00000000e+00 8.76410246e-01 ... 0.00000000e+00\n",
            "    9.39416289e-01 6.02829754e-01]\n",
            "   [3.60967088e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    3.30026835e-01 2.19684690e-02]\n",
            "   [8.57618749e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    1.01136394e-01 0.00000000e+00]]\n",
            "\n",
            "  [[0.00000000e+00 0.00000000e+00 1.07258177e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 2.13870290e-03 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   ...\n",
            "   [4.04471493e+00 0.00000000e+00 6.31025553e-01 ... 0.00000000e+00\n",
            "    4.61144865e-01 8.69948328e-01]\n",
            "   [5.40730906e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    1.68382928e-01 4.53967661e-01]\n",
            "   [1.02591658e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    3.09061334e-02 1.49397895e-01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 6.91324696e-02]\n",
            "   ...\n",
            "   [0.00000000e+00 4.32040244e-01 5.72181642e-01 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 2.21612126e-01 5.08052528e-01 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 9.24670577e-01 1.55271545e-01 ... 0.00000000e+00\n",
            "    1.07137486e-01 0.00000000e+00]]\n",
            "\n",
            "  [[7.47267157e-02 0.00000000e+00 0.00000000e+00 ... 6.20257258e-01\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 2.66644746e-01 6.92311823e-02 ... 8.44167396e-02\n",
            "    0.00000000e+00 5.13974242e-02]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 1.76609710e-01]\n",
            "   ...\n",
            "   [0.00000000e+00 1.15652823e+00 0.00000000e+00 ... 3.46322060e-01\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 1.05139822e-01 0.00000000e+00 ... 9.32996497e-02\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    2.70334125e-01 1.82468653e-01]]\n",
            "\n",
            "  [[1.26486108e-01 1.54642403e+00 0.00000000e+00 ... 1.37455595e+00\n",
            "    0.00000000e+00 3.67125005e-01]\n",
            "   [0.00000000e+00 5.18420935e-01 0.00000000e+00 ... 6.79544389e-01\n",
            "    0.00000000e+00 2.44946778e-01]\n",
            "   [0.00000000e+00 1.08149338e+00 9.71405447e-01 ... 6.38076570e-03\n",
            "    0.00000000e+00 1.64936364e-01]\n",
            "   ...\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 5.13700068e-01\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    0.00000000e+00 0.00000000e+00]\n",
            "   [2.98660606e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
            "    1.03287160e-01 0.00000000e+00]]]]\n",
            "[array([[[[0.00000000e+00, 4.31867003e-01, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
            "         [0.00000000e+00, 0.00000000e+00, 1.26274526e-01, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
            "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
            "         ...,\n",
            "         [1.54062402e+00, 4.78087544e-01, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 7.73721933e-01, 2.30732709e-01],\n",
            "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
            "         [0.00000000e+00, 2.23332345e-01, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
            "\n",
            "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
            "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
            "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
            "         ...,\n",
            "         [4.26317501e+00, 0.00000000e+00, 8.76410246e-01, ...,\n",
            "          0.00000000e+00, 9.39416289e-01, 6.02829754e-01],\n",
            "         [3.60967088e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 3.30026835e-01, 2.19684690e-02],\n",
            "         [8.57618749e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 1.01136394e-01, 0.00000000e+00]],\n",
            "\n",
            "        [[0.00000000e+00, 0.00000000e+00, 1.07258177e+00, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
            "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
            "         [0.00000000e+00, 0.00000000e+00, 2.13870290e-03, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
            "         ...,\n",
            "         [4.04471493e+00, 0.00000000e+00, 6.31025553e-01, ...,\n",
            "          0.00000000e+00, 4.61144865e-01, 8.69948328e-01],\n",
            "         [5.40730906e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 1.68382928e-01, 4.53967661e-01],\n",
            "         [1.02591658e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 3.09061334e-02, 1.49397895e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
            "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
            "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 6.91324696e-02],\n",
            "         ...,\n",
            "         [0.00000000e+00, 4.32040244e-01, 5.72181642e-01, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
            "         [0.00000000e+00, 2.21612126e-01, 5.08052528e-01, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
            "         [0.00000000e+00, 9.24670577e-01, 1.55271545e-01, ...,\n",
            "          0.00000000e+00, 1.07137486e-01, 0.00000000e+00]],\n",
            "\n",
            "        [[7.47267157e-02, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          6.20257258e-01, 0.00000000e+00, 0.00000000e+00],\n",
            "         [0.00000000e+00, 2.66644746e-01, 6.92311823e-02, ...,\n",
            "          8.44167396e-02, 0.00000000e+00, 5.13974242e-02],\n",
            "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 1.76609710e-01],\n",
            "         ...,\n",
            "         [0.00000000e+00, 1.15652823e+00, 0.00000000e+00, ...,\n",
            "          3.46322060e-01, 0.00000000e+00, 0.00000000e+00],\n",
            "         [0.00000000e+00, 1.05139822e-01, 0.00000000e+00, ...,\n",
            "          9.32996497e-02, 0.00000000e+00, 0.00000000e+00],\n",
            "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 2.70334125e-01, 1.82468653e-01]],\n",
            "\n",
            "        [[1.26486108e-01, 1.54642403e+00, 0.00000000e+00, ...,\n",
            "          1.37455595e+00, 0.00000000e+00, 3.67125005e-01],\n",
            "         [0.00000000e+00, 5.18420935e-01, 0.00000000e+00, ...,\n",
            "          6.79544389e-01, 0.00000000e+00, 2.44946778e-01],\n",
            "         [0.00000000e+00, 1.08149338e+00, 9.71405447e-01, ...,\n",
            "          6.38076570e-03, 0.00000000e+00, 1.64936364e-01],\n",
            "         ...,\n",
            "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          5.13700068e-01, 0.00000000e+00, 0.00000000e+00],\n",
            "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
            "         [2.98660606e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
            "          0.00000000e+00, 1.03287160e-01, 0.00000000e+00]]]],\n",
            "      dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MNoKPRGDKZ9o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "89a3106b-3374-42bc-a83d-94b28116046d"
      },
      "source": [
        "#for output, change this image path\n",
        "\n",
        "\n",
        "img_path = \"gdrive/My Drive/image_dataset/data_set/shoes/00000302.jpg\"\n",
        "            \n",
        "image2 = image.load_img(img_path, target_size=(299,299))\n",
        "image2 = image.img_to_array(image2)\n",
        "print(image2.shape)\n",
        "image2 = np.expand_dims(image2, axis=0)\n",
        "print(image2.shape)\n",
        "image2 = preprocess_input(image2)\n",
        "output = model.predict(image2)\n",
        "print(output[0])\n",
        "lis = list(output[0])\n",
        "out = (max(output[0]))\n",
        "print(out)\n",
        "l = lis.index(out)\n",
        "print(l)\n",
        "if l == 0:\n",
        "  print(\"its a dress\")\n",
        "  #auto encoder for dress\n",
        "elif l == 1:\n",
        "   print(\"its a shirt\")\n",
        "  #autoencoder for shirt\n",
        "elif l == 2 :\n",
        "   print(\"its a shoe\")\n",
        "  #autoencoder for shoe\n",
        "else:\n",
        "   print(\"its a short\")\n",
        "  # autoencoder for short"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(299, 299, 3)\n",
            "(1, 299, 299, 3)\n",
            "[1.48195602e-06 8.14806526e-07 1.13706647e-05 9.99975204e-01\n",
            " 1.10727315e-05]\n",
            "0.9999752\n",
            "3\n",
            "its a short\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}